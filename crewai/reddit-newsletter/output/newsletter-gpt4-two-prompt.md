### ANSWER 1

Here's a list of new AI projects or tools mentioned in the LocalLLama subreddit threads, along with their associated hyperlinks:

[**TinyDolphin 2.8 1.1B**](https://huggingface.co/Crataco/TinyDolphin-2.8-1.1b-imatrix-GGUF)  
[**Dolphin 2.6 Phi-2**](https://huggingface.co/TheBloke/dolphin-2_6-phi-2-GGUF)  
[**Nous Hermes Mistral 7B DPO**](https://huggingface.co/Crataco/Nous-Hermes-2-Mistral-7B-DPO-imatrix-GGUF)  
[**Nous Hermes 2 SOLAR 10.7B**](https://huggingface.co/TheBloke/Nous-Hermes-2-SOLAR-10.7B-GGUF)  
[**Nous Hermes 2 Mixtral 8x7B DPO**](https://huggingface.co/mradermacher/Nous-Hermes-2-Mixtral-8x7B-DPO-i1-GGUF)  
[**Kunoichi-DPO-v2-7B**](https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF)  
[**Erosumika**](https://huggingface.co/Lewdiculous/Erosumika-7B-GGUF-IQ-Imatrix)  
[**Fimbulvetr-11B-v2**](https://huggingface.co/mradermacher/Fimbulvetr-11B-v2-i1-GGUF)  
[**BagelMIsteryTour-v2-8x7B**](https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B-GGUF)  
[**ollama**](https://github.com/ollama/ollama)  
[**llama.cpp**](https://github.com/ggerganov/llama.cpp)  
[**SillyTavern**](https://github.com/SillyTavern/SillyTavern) with [**KoboldCpp**](https://github.com/LostRuins/koboldcpp)  
[**Endevor/InfinityRP-v1-7B**](https://huggingface.co/Endevor/InfinityRP-v1-7B) and [**InfinityRP-v1-7B-GGUF-IQ-Imatrix**](https://huggingface.co/Lewdiculous/InfinityRP-v1-7B-GGUF-IQ-Imatrix)  
[**ChaoticNeutrals/BuRP_7B**](https://huggingface.co/ChaoticNeutrals/BuRP_7B) and [**BuRP_7B-GGUF-IQ-Imatrix**](https://huggingface.co/Lewdiculous/BuRP_7B-GGUF-IQ-Imatrix)  
[**ChaoticNeutrals/Layris_9B**](https://huggingface.co/ChaoticNeutrals/Layris_9B) and [**Layris_9B-GGUF-IQ-Imatrix**](https://huggingface.co/Lewdiculous/Layris_9B-GGUF-IQ-Imatrix)  
[**Nitral-AI/Infinitely-Laydiculous-7B**](https://huggingface.co/Nitral-AI/Infinitely-Laydiculous-7B) and [**Infinitely-Laydiculous-7B-GGUF-IQ-Imatrix**](https://huggingface.co/Lewdiculous/Infinitely-Laydiculous-7B-GGUF-IQ-Imatrix)  
[**SanjiWatsuki/Kunoichi-DPO-v2-7B**](https://huggingface.co/SanjiWatsuki/Kunoichi-DPO-v2-7B) and [**Kunoichi-DPO-v2-7B-GGUF-Imatrix**](https://huggingface.co/Lewdiculous/Kunoichi-DPO-v2-7B-GGUF-Imatrix)  
[**l3utterfly/mistral-7b-v0.1-layla-v4**](https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v4/) and [**mistral-7b-v0.1-layla-v4-GGUF-IQ-Imatrix**](https://huggingface.co/Lewdiculous/mistral-7b-v0.1-layla-v4-G

### ANSWER 2

## [TinyDolphin 2.8 1.1B](https://huggingface.co/Crataco/TinyDolphin-2.8-1.1b-imatrix-GGUF)

- "Takes about ~700MB RAM and tested on my Pi 4 with 2 gigs of RAM. Hallucinates a lot, but works for basic conversation."
- This project demonstrates a trend toward more efficient AI models that can operate on lower-end hardware, making AI more accessible.

## [Dolphin 2.6 Phi-2](https://huggingface.co/TheBloke/dolphin-2_6-phi-2-GGUF)

- "Takes over ~2GB RAM and tested on my 3GB 32-bit phone via llama.cpp on Termux."
- This indicates a move towards mobile-friendly AI models, emphasizing the portability and accessibility of AI technologies.

## [Nous Hermes Mistral 7B DPO](https://huggingface.co/Crataco/Nous-Hermes-2-Mistral-7B-DPO-imatrix-GGUF)

- "Takes about ~4-5GB RAM depending on context length. Works on my laptop with 8GB RAM."
- Reflects the trend of developing more powerful AI models that remain efficient enough for use on standard consumer-grade computers.

## [Nous Hermes 2 SOLAR 10.7B](https://huggingface.co/TheBloke/Nous-Hermes-2-SOLAR-10.7B-GGUF)

- "Takes about ~6-8GB RAM depending on context length. Works on my server PCs and my primary PC (16GB RAM, 4GB VRAM)."
- This project aligns with the trend of scaling AI models to leverage higher computational power for more advanced tasks.

## [Nous Hermes 2 Mixtral 8x7B DPO](https://huggingface.co/mradermacher/Nous-Hermes-2-Mixtral-8x7B-DPO-i1-GGUF)

- "At IQ3_S, it can run on a laptop with 16GB RAM and 8GB VRAM with 10-11 layers offloaded at 4096 ctx, but I recall it's slightly slower than Q3_K_S."
- Demonstrates advancements in model efficiency and layer offloading, crucial for deploying large models on relatively accessible hardware.

## [Kunoichi-DPO-v2-7B](https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF)

- "My most reliable."
- Indicates a focus on reliability and consistency in AI model development, which is vital for user trust and widespread adoption.

## [Erosumika](https://huggingface.co/Lewdiculous/Erosumika-7B-GGUF-IQ-Imatrix)

- "Sacrifices the logical yet synthetic GPT dataset for something more organic, similar to older models."
- Reflects a trend towards more human-like, organic interactions in AI, moving away from purely data-driven responses.

## [Fimbulvetr-11B-v2](https://huggingface.co/mradermacher/Fimbulvetr-11B-v2-i1-GGUF)

- "I haven't tested it nearly as much as Kunoichi, so I can't vouch for it, but I hear a lot of great things about it!"
- This highlights the community-driven aspect of AI development, where reputation and peer feedback play a significant role in a project's adoption.

## [BagelMIsteryTour-v2-8x7B](https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B-GGUF)

- "Probably the best RP model I've ever ran since it hits a great balance of prose and intelligence."
- Shows the ongoing effort to balance different AI capabilities, such as linguistic prowess and cognitive intelligence, for more engaging interactions.

## [ollama](https://github.com/ollama/ollama)

- "I use it for quick Q&A. Automatically offloads GPU layers, easy to download and get a model running."
- Illustrates the trend towards user-friendly AI tools that simplify the process of utilizing complex models.

## [llama.cpp](https://github.com/ggerganov/llama.cpp)

- "With cmake, I was able to compile the latest commit on my 32-bit Android phone."
- Emphasizes the trend towards cross-platform compatibility in AI tools, broadening their usability across different devices.

## [SillyTavern](https://github.com/SillyTavern/SillyTavern) with [KoboldCpp](https://github.com/LostRuins/koboldcpp)

- "For roleplay, or just because of its fancy interface, usually if I'm
