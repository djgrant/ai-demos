Here is a report highlighting the new AI projects or tools from the provided LocalLLama subreddit data:

## [TinyDolphin 2.8 1.1B](https://huggingface.co/Crataco/TinyDolphin-2.8-1.1b-imatrix-GGUF)

- "Takes about ~700MB RAM and tested on my Pi 4 with 2 gigs of RAM. Hallucinates a lot, but works for basic conversation."
- This is a compact 1.1B parameter model aimed at running on lower-end hardware like the Raspberry Pi. The trend of making AI models more efficient and accessible aligns with the growing democratization of AI.

## [Dolphin 2.6 Phi-2](https://huggingface.co/TheBloke/dolphin-2_6-phi-2-GGUF)

- "Takes over ~2GB RAM and tested on my 3GB 32-bit phone via llama.cpp on Termux."
- Another efficient 2.7B model designed to run on mobile devices. Enabling AI capabilities on smartphones and low-cost hardware expands access to a wider user base.

## [Nous Hermes Mistral 7B DPO](https://huggingface.co/Crataco/Nous-Hermes-2-Mistral-7B-DPO-imatrix-GGUF)

- No direct comments.
- A 7B instruction-tuned model, likely intended for general tasks. Mid-sized models strike a balance between capability and resource requirements.

## [Nous Hermes 2 SOLAR 10.7B](https://huggingface.co/TheBloke/Nous-Hermes-2-SOLAR-10.7B-GGUF)

- No direct comments.
- At 10.7B parameters, this model offers more power than the 7B variants, though requiring more resources. Larger models continue pushing AI capabilities.

## [Nous Hermes 2 Mixtral 8x7B DPO](https://huggingface.co/mradermacher/Nous-Hermes-2-Mixtral-8x7B-DPO-i1-GGUF)

- "At IQ3_S, it can run on a laptop with 16GB RAM and 8GB VRAM with 10-11 layers offloaded at 4096 ctx."
- This 8x7B multi-model exploits model parallelism for greater capability than single models, representing an AI scaling technique.

## [Kunoichi-DPO-v2-7B](https://huggingface.co/brittlewis12/Kunoichi-DPO-v2-7B-GGUF)

- "My most reliable, but I **love** [Erosumika](https://huggingface.co/Lewdiculous/Erosumika-7B-GGUF-IQ-Imatrix), which sacrifices the logical yet synthetic GPT dataset for something more organic."
- Role-playing oriented 7B models, tapping into the creative AI use case beyond just Q&A.

## [Fimbulvetr-11B-v2](https://huggingface.co/mradermacher/Fimbulvetr-11B-v2-i1-GGUF)

- "I haven't tested it nearly as much as Kunoichi, so I can't vouch for it, but I hear a lot of great things about it!"
- Another role-playing model at 11B parameters.

## [BagelMIsteryTour-v2-8x7B](https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B-GGUF)

- "Probably the best RP model I've ever ran since it hits a great balance of prose and intelligence."
- An 8x7B multi-model optimized for role-playing tasks, combining scale with creative writing ability.

## [ollama](https://github.com/ollama/ollama) & [llama.cpp](https://github.com/ggerganov/llama.cpp)

- "Terminal client. I use it for quick Q&A. Automatically offloads GPU layers, easy to download and get a model running..."
- These are user interfaces or front-ends for running local LLM models from a terminal.

## [SillyTavern](https://github.com/SillyTavern/SillyTavern)

- "For roleplay, or just because of its fancy interface, usually if I'm using a model hosted from another PC, want to do a roleplay, or use its built-in RAG capability."
- An interface optimized for roleplay and other creative AI use cases.

## [Westlake-10.7B-v2](https://huggingface.co/Westlake-10.7B-v2)

- "You could stop here and just get this one and you will leave this thread happy."
- A 10.7B model praised for its performance on risque/mature content generation.

## [Noromaid Variants](https://huggingface.co/Crataco/TinyDolphin-2.8-1.1b-imatrix-GGUF)

- "Anything with Noromaid in it is a staple of rip your clothes off style raunch..."
- Variants of the Noromaid model optimized for mature/adult content generation.

## [Midnight-Rose & Midnight-Miqu](https://huggingface.co/Midnight-Miqu)

- "For a more intelligent good time with a slower burn..."
- 70B+ models geared towards creative and mature writing tasks.

## [InfinityRP 7B](https://huggingface.co/Endevor/InfinityRP-v1-7B)

- "This model was basically made to stop some upsetting hallucinations..."
- A 7B roleplay model aiming to reduce problematic outputs.

## [BuRP 7B](https://huggingface.co/ChaoticNeutrals/BuRP_7B)

- "So you want a model that can do it all? You've been dying to RP with a superintelligence who never refuses your advances..."
- Another 7B variant focused on unrestrained roleplay capabilities.

## [Layris 9B](https://huggingface.co/ChaoticNeutrals/Layris_9B)

- "This passthrough Eris merge aimed to bring a high scoring model together with Layla-V4."
- A 9B model resulting from merging techniques applied to other open models.

## [Infinitely-Laydiculous 7B](https://huggingface.co/Nitral-AI/Infinitely-Laydiculous-7B)

- "I really like InfinityRP's style, and wanted to see it merged with Layla-V4 for her absolute unhingedness/unalignment."
- Yet another creative 7B model variant produced through merging techniques.

## [Layla-V4 7B](https://huggingface.co/l3utterfly/mistral-7b-v0.1-layla-v4)

- "This model has been stripped out of all refusals. A truly based and unaligned breed that is solid for roleplaying."
- A customized 7B focused on removing output censoring for unrestricted roleplaying.

## [Kunocchini 7B](https://huggingface.co/Nitral-AI/Kunocchini-7b-128k-test)

- "Kunoichi-DPO-v2 with better handling of longer contexts."
- A variant of the Kunoichi model optimized for longer context handling.

## [miquliz-120b-v2.0](https://huggingface.co/wolfram/miquliz-120b-v2.0)

- "I've been running [wolfram/miquliz-120b-v2.0](https://huggingface.co/wolfram/miquliz-120b-v2.0) almost exclusively since making it."
- A powerful 120B multi-model from the Miqu series.

## [mistral_7b_instruct_v0.2_DARE](https://huggingface.co/mistral_7b_instruct_v0.2_DARE)

- "It's repeating some stuff but overall it shown better accuracy and less hallucinations in describing images than yi-vl-34b."
- An instruction-tuned 7B Mistral model optimized for multimodal and image description tasks.

## [Mistral 7B Instruct v0.2](https://huggingface.co/mistral_7b_instruct_v0.2)

- "The best all-round daily task: full 32k contexts, fast, affordable, good foreign language, somewhat uncensored, and good for RAG tasks."
- Another strong general instruction model variant in the popular Mistral series.

## [Mixtral 8x7B](https://huggingface.co/ycros/BagelMIsteryTour-v2-8x7B-GGUF)

- No direct comments, but compared favorably to the 7B Mistral variant.
- The multi-model 8x7B parallel instance taking the Mistral series to greater scale.
